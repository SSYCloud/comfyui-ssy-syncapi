import os
import json
import base64
import requests
from io import BytesIO
from PIL import Image
import torch
import numpy as np

p = os.path.dirname(os.path.realpath(__file__))

def get_config():
    try:
        config_path = os.path.join(p, 'config.json')
        with open(config_path, 'r') as f:  
            config = json.load(f)
        return config
    except:
        return {}

def save_config(config):
    config_path = os.path.join(p, 'config.json')
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=4)

class SSYAPIBase:
    """SSY Cloud APIåŸºç¡€ç±»"""
    
    def __init__(self):
        env_key = os.environ.get("SSY_API_KEY")
        placeholders = {"token_here", "place_token_here", "your_api_key",
                        "api_key_here", "enter_your_key", "<api_key>"}

        if env_key and env_key.lower().strip() not in placeholders:
            self.api_key = env_key
        else:
            config = get_config()
            self.api_key = config.get("SSY_API_KEY")

    def tensor_to_image(self, tensor):
        """Convert tensor to PIL Image"""
        tensor = tensor.cpu()
        if len(tensor.shape) == 4:
            tensor = tensor.squeeze(0) if tensor.shape[0] == 1 else tensor[0]
        
        image_np = tensor.squeeze().mul(255).clamp(0, 255).byte().numpy()
        return Image.fromarray(image_np, mode='RGB')

    def create_placeholder_image(self, width=512, height=512):
        """Create a placeholder image when generation fails"""
        img = Image.new('RGB', (width, height), color=(100, 100, 100))
        try:
            from PIL import ImageDraw
            draw = ImageDraw.Draw(img)
            draw.text((width//2-50, height//2), "Generation\nFailed", fill=(255, 255, 255))
        except:
            pass
        
        image_array = np.array(img).astype(np.float32) / 255.0
        return torch.from_numpy(image_array).unsqueeze(0)

    def call_ssy_api(self, data, endpoint="generations"):
        """è°ƒç”¨SSY Cloud API
        
        Args:
            data: è¯·æ±‚æ•°æ®
            endpoint: APIç«¯ç‚¹ï¼Œ"generations" æˆ– "edits"
        """
        try:
            url = f"https://router.shengsuanyun.com/api/v1/images/{endpoint}"
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            operation_log = f"è°ƒç”¨API: {data.get('model', 'unknown')}\n"
            operation_log += f"ç«¯ç‚¹: {url}\n"
            operation_log += f"è¯·æ±‚å‚æ•°: {list(data.keys())}\n"
            
            # æ‰“å°å®Œæ•´è¯·æ±‚ä½“ï¼ˆéšè—å›¾ç‰‡æ•°æ®ï¼‰
            debug_data = data.copy()
            if 'image' in debug_data and isinstance(debug_data['image'], str) and len(debug_data['image']) > 100:
                debug_data['image'] = f"<base64 data {len(debug_data['image'])} chars>"
            if 'images' in debug_data:
                debug_data['images'] = f"<{len(debug_data['images'])} images>"
            operation_log += f"è¯·æ±‚ä½“: {json.dumps(debug_data, ensure_ascii=False, indent=2)}\n"
            
            # å‘é€è¯·æ±‚
            response = requests.post(url, headers=headers, json=data, timeout=120)
            
            # è®°å½•å“åº”çŠ¶æ€
            operation_log += f"å“åº”çŠ¶æ€ç : {response.status_code}\n"
            
            # å°è¯•è§£æJSON
            try:
                result = response.json()
                operation_log += f"å“åº”é”®: {list(result.keys())}\n"
            except:
                operation_log += f"å“åº”æ–‡æœ¬: {response.text[:500]}\n"
                response.raise_for_status()
                return [], operation_log
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if "error" in result:
                operation_log += f"APIé”™è¯¯: {result['error']}\n"
                return [], operation_log
            
            all_images = []
            
            # æ ¼å¼1: Google Geminiæ ¼å¼ (candidates)
            if "candidates" in result:
                operation_log += "ä½¿ç”¨Geminiå“åº”æ ¼å¼\n"
                for candidate in result["candidates"]:
                    if "content" in candidate and "parts" in candidate["content"]:
                        for part in candidate["content"]["parts"]:
                            if "inlineData" in part and "data" in part["inlineData"]:
                                try:
                                    img_data = base64.b64decode(part["inlineData"]["data"])
                                    img = Image.open(BytesIO(img_data))
                                    if img.mode != "RGB":
                                        img = img.convert("RGB")
                                    img_np = np.array(img).astype(np.float32) / 255.0
                                    img_tensor = torch.from_numpy(img_np)[None,]
                                    all_images.append(img_tensor)
                                except Exception as e:
                                    operation_log += f"è§£æGeminiå›¾åƒå¤±è´¥: {str(e)}\n"
            
            # æ ¼å¼2: OpenAI/Doubaoæ ¼å¼ (dataæ•°ç»„)
            elif "data" in result and isinstance(result["data"], list):
                operation_log += "ä½¿ç”¨OpenAI/Doubaoå“åº”æ ¼å¼\n"
                for item in result["data"]:
                    try:
                        # b64_jsonæ ¼å¼
                        if "b64_json" in item:
                            img_data = base64.b64decode(item["b64_json"])
                            img = Image.open(BytesIO(img_data))
                            if img.mode != "RGB":
                                img = img.convert("RGB")
                            img_np = np.array(img).astype(np.float32) / 255.0
                            img_tensor = torch.from_numpy(img_np)[None,]
                            all_images.append(img_tensor)
                        # URLæ ¼å¼
                        elif "url" in item:
                            img_response = requests.get(item["url"], timeout=30)
                            img = Image.open(BytesIO(img_response.content))
                            if img.mode != "RGB":
                                img = img.convert("RGB")
                            img_np = np.array(img).astype(np.float32) / 255.0
                            img_tensor = torch.from_numpy(img_np)[None,]
                            all_images.append(img_tensor)
                    except Exception as e:
                        operation_log += f"è§£ædataæ•°ç»„å›¾åƒå¤±è´¥: {str(e)}\n"
            
            # æ ¼å¼3: ç«å±±å¼•æ“æ ¼å¼ (ç‰¹æ®Šç»“æ„)
            elif "data" in result and isinstance(result["data"], dict):
                operation_log += "ä½¿ç”¨ç«å±±å¼•æ“å“åº”æ ¼å¼\n"
                try:
                    data_obj = result["data"]
                    # å°è¯•ä»binary_data_base64è·å–
                    if "binary_data_base64" in data_obj and data_obj["binary_data_base64"]:
                        for b64_str in data_obj["binary_data_base64"]:
                            img_data = base64.b64decode(b64_str)
                            img = Image.open(BytesIO(img_data))
                            if img.mode != "RGB":
                                img = img.convert("RGB")
                            img_np = np.array(img).astype(np.float32) / 255.0
                            img_tensor = torch.from_numpy(img_np)[None,]
                            all_images.append(img_tensor)
                    # å°è¯•ä»image_urlsè·å–
                    elif "image_urls" in data_obj and data_obj["image_urls"]:
                        for url in data_obj["image_urls"]:
                            img_response = requests.get(url, timeout=30)
                            img = Image.open(BytesIO(img_response.content))
                            if img.mode != "RGB":
                                img = img.convert("RGB")
                            img_np = np.array(img).astype(np.float32) / 255.0
                            img_tensor = torch.from_numpy(img_np)[None,]
                            all_images.append(img_tensor)
                except Exception as e:
                    operation_log += f"è§£æç«å±±å¼•æ“æ ¼å¼å¤±è´¥: {str(e)}\n"
            
            # æ ¼å¼4: ç›´æ¥imageå­—æ®µ
            elif "image" in result:
                operation_log += "ä½¿ç”¨imageå­—æ®µå“åº”æ ¼å¼\n"
                try:
                    if isinstance(result["image"], str):
                        img_data = base64.b64decode(result["image"])
                        img = Image.open(BytesIO(img_data))
                        if img.mode != "RGB":
                            img = img.convert("RGB")
                        img_np = np.array(img).astype(np.float32) / 255.0
                        img_tensor = torch.from_numpy(img_np)[None,]
                        all_images.append(img_tensor)
                except Exception as e:
                    operation_log += f"è§£æimageå­—æ®µå¤±è´¥: {str(e)}\n"
            
            # æ ¼å¼5: resultsæ•°ç»„ (æŸäº›APIå¯èƒ½ä½¿ç”¨)
            elif "results" in result and isinstance(result["results"], list):
                operation_log += "ä½¿ç”¨resultsæ•°ç»„å“åº”æ ¼å¼\n"
                for item in result["results"]:
                    try:
                        if "image" in item:
                            img_data = base64.b64decode(item["image"])
                            img = Image.open(BytesIO(img_data))
                            if img.mode != "RGB":
                                img = img.convert("RGB")
                            img_np = np.array(img).astype(np.float32) / 255.0
                            img_tensor = torch.from_numpy(img_np)[None,]
                            all_images.append(img_tensor)
                        elif "url" in item:
                            img_response = requests.get(item["url"], timeout=30)
                            img = Image.open(BytesIO(img_response.content))
                            if img.mode != "RGB":
                                img = img.convert("RGB")
                            img_np = np.array(img).astype(np.float32) / 255.0
                            img_tensor = torch.from_numpy(img_np)[None,]
                            all_images.append(img_tensor)
                    except Exception as e:
                        operation_log += f"è§£æresultså›¾åƒå¤±è´¥: {str(e)}\n"
            
            if all_images:
                operation_log += f"âœ“ æˆåŠŸè§£æ {len(all_images)} å¼ å›¾åƒ\n"
            else:
                operation_log += "âœ— æœªèƒ½ä»å“åº”ä¸­è§£æå‡ºå›¾åƒ\n"
                operation_log += f"å®Œæ•´å“åº”ç»“æ„: {json.dumps(result, ensure_ascii=False, indent=2)[:1000]}\n"
            
            return all_images, operation_log
            
        except requests.exceptions.RequestException as e:
            operation_log = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}\n"
            return [], operation_log
        except Exception as e:
            operation_log = f"APIè°ƒç”¨é”™è¯¯: {str(e)}\n"
            import traceback
            operation_log += f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}\n"
            return [], operation_log


class SSYGoogleGenerator(SSYAPIBase):
    """Google Geminiç³»åˆ—å›¾åƒç”Ÿæˆå™¨"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": (["google/gemini-2.5-flash-image-preview", "google/gemini-3-pro-image-preview"], {
                    "default": "google/gemini-2.5-flash-image-preview"
                }),
                "prompt": ("STRING", {
                    "default": "Generate a high-quality, photorealistic image", 
                    "multiline": True
                }),
            },
            "optional": {
                "input_image": ("IMAGE", {"tooltip": "ç¬¬1å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image1": ("IMAGE", {"tooltip": "ç¬¬2å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image2": ("IMAGE", {"tooltip": "ç¬¬3å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image3": ("IMAGE", {"tooltip": "ç¬¬4å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image4": ("IMAGE", {"tooltip": "ç¬¬5å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image5": ("IMAGE", {"tooltip": "ç¬¬6å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image6": ("IMAGE", {"tooltip": "ç¬¬7å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image7": ("IMAGE", {"tooltip": "ç¬¬8å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image8": ("IMAGE", {"tooltip": "ç¬¬9å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image9": ("IMAGE", {"tooltip": "ç¬¬10å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image10": ("IMAGE", {"tooltip": "ç¬¬11å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image11": ("IMAGE", {"tooltip": "ç¬¬12å¼ å‚è€ƒå›¾ç‰‡"}),
                "api_key": ("STRING", {
                    "default": "",
                    "password": True
                }),
                "aspect_ratio": (["1:1", "16:9", "21:9", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16"], {
                    "default": "1:1"
                }),
                "size": (["1K", "2K", "4K"], {
                    "default": "1K",
                    "tooltip": "ä»…gemini-3-pro-image-previewæ”¯æŒ"
                }),
                "response_modalities": (["IMAGE", "TEXT_IMAGE"], {
                    "default": "IMAGE"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "log")
    FUNCTION = "generate"
    CATEGORY = "SSY CloudåŒæ­¥ä»»åŠ¡/Google"

    def generate(self, model, prompt, input_image=None, input_image1=None, input_image2=None, 
                input_image3=None, input_image4=None, input_image5=None, input_image6=None,
                input_image7=None, input_image8=None, input_image9=None, input_image10=None,
                input_image11=None, api_key="", aspect_ratio="1:1", size="1K", 
                response_modalities="IMAGE"):
        if api_key.strip():
            self.api_key = api_key
            save_config({"SSY_API_KEY": self.api_key})

        if not self.api_key:
            return (self.create_placeholder_image(), "é”™è¯¯: æœªæä¾›APIå¯†é’¥")

        try:
            data = {
                "model": model,
                "prompt": prompt,
                "aspect_ratio": aspect_ratio
            }
            
            # å¤„ç†å¤šå¼ å›¾åƒï¼ˆæœ€å¤š12å¼ ï¼‰
            all_input_images = [input_image, input_image1, input_image2, input_image3, input_image4,
                              input_image5, input_image6, input_image7, input_image8, input_image9,
                              input_image10, input_image11]
            
            images_data = []
            for img in all_input_images:
                if img is not None:
                    if isinstance(img, torch.Tensor):
                        pil_image = self.tensor_to_image(img[0] if len(img.shape) == 4 else img)
                        img_byte_arr = BytesIO()
                        pil_image.save(img_byte_arr, format='PNG')
                        b64_string = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
                        images_data.append({
                            "inline_data": {
                                "mime_type": "image/png",
                                "data": b64_string
                            }
                        })
            
            if images_data:
                data["images"] = images_data
            
            # gemini-3-proç‹¬æœ‰å‚æ•°
            if "gemini-3-pro" in model:
                data["size"] = size
            
            # response_modalities
            if response_modalities == "IMAGE":
                data["response_modalities"] = ["IMAGE"]
            else:
                data["response_modalities"] = ["TEXT", "IMAGE"]
            
            # è±†åŒ…ç³»åˆ—ä½¿ç”¨generationsç«¯ç‚¹
            images, log = self.call_ssy_api(data, endpoint="generations")
            
            if images:
                return (torch.cat(images, dim=0), log)
            else:
                return (self.create_placeholder_image(), log)
                
        except Exception as e:
            return (self.create_placeholder_image(), f"é”™è¯¯: {str(e)}")


class SSYDoubaoGenerator(SSYAPIBase):
    """ByteDance Doubaoç³»åˆ—å›¾åƒç”Ÿæˆå™¨ - ç®€åŒ–ç‰ˆ"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ([
                    "bytedance/doubao-seedream-4.5",
                    "bytedance/doubao-seedream-4.0",
                    "bytedance/doubao-seedream-3.0-t2i",
                    "bytedance/doubao-seededit-3-0-i2i"
                ], {
                    "default": "bytedance/doubao-seedream-4.5"
                }),
                "prompt": ("STRING", {
                    "default": "Generate a high-quality image", 
                    "multiline": True
                }),
            },
            "optional": {
                "input_image": ("IMAGE", {"tooltip": "ç¬¬1å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image1": ("IMAGE", {"tooltip": "ç¬¬2å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image2": ("IMAGE", {"tooltip": "ç¬¬3å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image3": ("IMAGE", {"tooltip": "ç¬¬4å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image4": ("IMAGE", {"tooltip": "ç¬¬5å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image5": ("IMAGE", {"tooltip": "ç¬¬6å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image6": ("IMAGE", {"tooltip": "ç¬¬7å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image7": ("IMAGE", {"tooltip": "ç¬¬8å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image8": ("IMAGE", {"tooltip": "ç¬¬9å¼ å‚è€ƒå›¾ç‰‡"}),
                "input_image9": ("IMAGE", {"tooltip": "ç¬¬10å¼ å‚è€ƒå›¾ç‰‡"}),
                "api_key": ("STRING", {
                    "default": "",
                    "password": True
                }),
                "size": (["1024x1024", "1536x1024", "1024x1536", "2048x2048"], {
                    "default": "1024x1024"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "log")
    FUNCTION = "generate"
    CATEGORY = "SSY CloudåŒæ­¥ä»»åŠ¡/Doubao"

    def generate(self, model, prompt, input_image=None, input_image1=None, input_image2=None,
                input_image3=None, input_image4=None, input_image5=None, input_image6=None,
                input_image7=None, input_image8=None, input_image9=None, api_key="", 
                size="1024x1024", watermark=False):
        if api_key.strip():
            self.api_key = api_key
            save_config({"SSY_API_KEY": self.api_key})

        if not self.api_key:
            return (self.create_placeholder_image(), "é”™è¯¯: æœªæä¾›APIå¯†é’¥")

        try:
            # æ„å»ºæœ€ç®€è¯·æ±‚ä½“
            data = {
                "model": model,
                "prompt": prompt,
                "size": size,
                "watermark": watermark
            }
            
            # å¤„ç†å¤šå¼ å›¾åƒï¼ˆæœ€å¤š10å¼ ï¼‰
            all_input_images = [input_image, input_image1, input_image2, input_image3, input_image4,
                              input_image5, input_image6, input_image7, input_image8, input_image9]
            
            images_data = []
            for img in all_input_images:
                if img is not None:
                    if isinstance(img, torch.Tensor):
                        pil_image = self.tensor_to_image(img[0] if len(img.shape) == 4 else img)
                        img_byte_arr = BytesIO()
                        pil_image.save(img_byte_arr, format='PNG')
                        b64_string = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
                        # ä½¿ç”¨data URIæ ¼å¼ï¼ˆæ ¹æ®APIæ–‡æ¡£è¦æ±‚ï¼‰
                        images_data.append(f"data:image/png;base64,{b64_string}")
            
            if images_data:
                # 4.0å’Œ4.5æ”¯æŒå¤šå›¾æ•°ç»„
                if "4.0" in model or "4.5" in model:
                    data["image"] = images_data
                else:
                    # 3.0ç³»åˆ—åªæ”¯æŒå•å›¾å­—ç¬¦ä¸²
                    data["image"] = images_data[0]
            
            # è±†åŒ…ç³»åˆ—ä½¿ç”¨generationsç«¯ç‚¹
            images, log = self.call_ssy_api(data, endpoint="generations")
            
            if images:
                return (torch.cat(images, dim=0), log)
            else:
                return (self.create_placeholder_image(), log)
                
        except Exception as e:
            return (self.create_placeholder_image(), f"é”™è¯¯: {str(e)}")


class SSYOpenAIGenerator(SSYAPIBase):
    """OpenAIç³»åˆ—å›¾åƒç”Ÿæˆå™¨"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": (["openai/gpt-image-1"], {
                    "default": "openai/gpt-image-1"
                }),
                "prompt": ("STRING", {
                    "default": "Generate a high-quality image", 
                    "multiline": True
                }),
            },
            "optional": {
                "input_image": ("IMAGE", {"tooltip": "å‚è€ƒå›¾ç‰‡"}),
                "api_key": ("STRING", {
                    "default": "",
                    "password": True
                }),
                "size": (["auto", "1024x1024", "1536x1024", "1024x1536", "1792x1024", "1024x1792"], {
                    "default": "auto"
                }),
                "n": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 10
                }),
                "quality": (["auto", "high", "medium", "low", "hd", "standard"], {
                    "default": "auto"
                }),
                "background": (["auto", "transparent", "opaque"], {
                    "default": "auto",
                    "tooltip": "transparentæ—¶éœ€ä½¿ç”¨pngæˆ–webpæ ¼å¼"
                }),
                "output_format": (["png", "jpeg", "webp"], {
                    "default": "png"
                }),
                "output_compression": ("INT", {
                    "default": 100,
                    "min": 0,
                    "max": 100,
                    "tooltip": "webpæˆ–jpegæ ¼å¼æ”¯æŒ"
                }),
                "moderation": (["auto", "low"], {
                    "default": "auto"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "log")
    FUNCTION = "generate"
    CATEGORY = "SSY CloudåŒæ­¥ä»»åŠ¡/OpenAI"

    def generate(self, model, prompt, input_image=None, api_key="", size="auto", n=1, quality="auto",
                background="auto", output_format="png", output_compression=100, moderation="auto"):
        if api_key.strip():
            self.api_key = api_key
            save_config({"SSY_API_KEY": self.api_key})

        if not self.api_key:
            return (self.create_placeholder_image(), "é”™è¯¯: æœªæä¾›APIå¯†é’¥")

        try:
            # æŒ‰ç…§APIæ–‡æ¡£æ„å»ºè¯·æ±‚ä½“ï¼Œä¸¤ä¸ªç«¯ç‚¹å‚æ•°å®Œå…¨ç›¸åŒ
            data = {
                "model": model,
                "prompt": prompt
            }
            
            # å¤„ç†è¾“å…¥å›¾åƒ
            has_image = False
            if input_image is not None:
                if isinstance(input_image, torch.Tensor):
                    pil_image = self.tensor_to_image(input_image[0] if len(input_image.shape) == 4 else input_image)
                    img_byte_arr = BytesIO()
                    pil_image.save(img_byte_arr, format='PNG')
                    b64_string = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
                    data["image"] = f"data:image/png;base64,{b64_string}"
                    has_image = True
            
            # æ·»åŠ å…¶ä»–å‚æ•°ï¼ˆæ–‡ç”Ÿå›¾å’Œå›¾ç”Ÿå›¾éƒ½æ”¯æŒï¼‰
            if n != 1:
                data["n"] = n
            if size != "auto":
                data["size"] = size
            if quality != "auto":
                data["quality"] = quality
            if output_format != "png":
                data["output_format"] = output_format
            if background != "auto":
                data["background"] = background
            if moderation != "auto":
                data["moderation"] = moderation
            if output_compression != 100:
                data["output_compression"] = output_compression
            
            # æ ¹æ®æ˜¯å¦æœ‰å›¾ç‰‡é€‰æ‹©ç«¯ç‚¹ï¼šæœ‰å›¾ç”¨editsï¼Œæ— å›¾ç”¨generations
            endpoint = "edits" if has_image else "generations"
            images, log = self.call_ssy_api(data, endpoint=endpoint)
            
            if images:
                return (torch.cat(images, dim=0), log)
            else:
                return (self.create_placeholder_image(), log)
                
        except Exception as e:
            return (self.create_placeholder_image(), f"é”™è¯¯: {str(e)}")


class SSYBytedanceProcessor(SSYAPIBase):
    """ç«å±±å¼•æ“å›¾åƒå¤„ç†å™¨ï¼ˆå¢å¼º/æ”¾å¤§ï¼‰"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": (["bytedance/image_enhance", "bytedance/image_upscale"], {
                    "default": "bytedance/image_enhance"
                }),
                "input_image": ("IMAGE", {}),
            },
            "optional": {
                "api_key": ("STRING", {
                    "default": "",
                    "password": True
                }),
                "model_quality": (["HQ", "MQ", "LQ"], {
                    "default": "MQ",
                    "tooltip": "upscaleæ¨¡å‹å¿…é€‰ï¼šHQé€‚ç”¨é«˜è´¨é‡å›¾ï¼ŒMQä¸­ç­‰ï¼ŒLQé€‚ç”¨ä½è´¨é‡å›¾"
                }),
                "resolution_boundary": (["144p", "240p", "360p", "480p", "540p", "720p", "1080p", "2k"], {
                    "default": "1080p"
                }),
                "jpg_quality": ("INT", {
                    "default": 95,
                    "min": 0,
                    "max": 100
                }),
                "result_format": ([0, 1], {
                    "default": 0,
                    "tooltip": "0=pngæ ¼å¼, 1=jpegæ ¼å¼"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "log")
    FUNCTION = "process"
    CATEGORY = "SSY CloudåŒæ­¥ä»»åŠ¡/Bytedance"

    def process(self, model, input_image, api_key="", model_quality="MQ", 
               resolution_boundary="1080p", jpg_quality=95, result_format=0):
        if api_key.strip():
            self.api_key = api_key
            save_config({"SSY_API_KEY": self.api_key})

        if not self.api_key:
            return (self.create_placeholder_image(), "é”™è¯¯: æœªæä¾›APIå¯†é’¥")

        try:
            # å¤„ç†å›¾åƒ
            if isinstance(input_image, torch.Tensor):
                pil_image = self.tensor_to_image(input_image[0] if len(input_image.shape) == 4 else input_image)
                img_byte_arr = BytesIO()
                pil_image.save(img_byte_arr, format='PNG')
                b64_string = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
            
            data = {
                "model": model,
                "binary_data_base64": [b64_string],
                "resolution_boundary": resolution_boundary,
                "jpg_quality": jpg_quality,
                "result_format": result_format,
                "return_url": True
            }
            
            # upscaleæ¨¡å‹å¿…é¡»çš„å‚æ•°
            if "upscale" in model:
                data["model_quality"] = model_quality
            
            # ç«å±±å¼•æ“ä½¿ç”¨editsç«¯ç‚¹
            images, log = self.call_ssy_api(data, endpoint="edits")
            
            if images:
                return (torch.cat(images, dim=0), log)
            else:
                return (self.create_placeholder_image(), log)
                
        except Exception as e:
            return (self.create_placeholder_image(), f"é”™è¯¯: {str(e)}")


# Node registration
NODE_CLASS_MAPPINGS = {
    "SSYGoogleGenerator": SSYGoogleGenerator,
    "SSYDoubaoGenerator": SSYDoubaoGenerator,
    "SSYOpenAIGenerator": SSYOpenAIGenerator,
    "SSYBytedanceProcessor": SSYBytedanceProcessor,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SSYGoogleGenerator": "SSY Google Generatorï¼ˆåŒæ­¥ä»»åŠ¡ï¼‰ğŸŒŸ",
    "SSYDoubaoGenerator": "SSY Doubao Generatorï¼ˆåŒæ­¥ä»»åŠ¡ï¼‰ğŸ¨",
    "SSYOpenAIGenerator": "SSY OpenAI Generatorï¼ˆåŒæ­¥ä»»åŠ¡ï¼‰ğŸ¤–",
    "SSYBytedanceProcessor": "SSY Bytedance Processorï¼ˆåŒæ­¥ä»»åŠ¡ï¼‰ğŸ”§",
}
